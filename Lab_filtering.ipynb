{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Modern Theory of Detection and Estimation**\n",
        "\n",
        "## **Lab 3: Stock Price Prediction. Comparing Wiener and Adaptive LMS Filters**\n",
        "### **Academic Year 2024/2025**\n",
        "\n",
        "Bachelor's Degree in:\n",
        "*   Mobile and Space Communications Engineering (Groups 61 and 65)\n",
        "*   Sound and Image Engineering (Groups 66 and 69)\n",
        "*   Telecommunication Technologies Engineering (Groups 91, 92, and 95)\n",
        "*   Telematics Engineering (Groups 71 and 79)\n",
        "\n",
        "\n",
        "\n",
        "**Signal Theory and Communications Department - UC3M**\n",
        "\n",
        "**University Carlos III of Madrid (UC3M)**"
      ],
      "metadata": {
        "id": "DlvJRRiGzTpE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Students information**\n",
        "\n",
        "**Surname(s) and name(s)**\n",
        "\n",
        "* Alonso Herreros Copete\n",
        "* Ismael MartÃ­n de Vidales MartÃ­n\n",
        "* Jose Alberto Pastor Llorente\n",
        "* Jorge Cuanda Alonso\n",
        "\n",
        "**Group:** 95\n",
        "\n",
        "**Date:**"
      ],
      "metadata": {
        "id": "7mgpQBrMeSsL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Logistics**\n",
        "\n",
        "**Due Date**:\n",
        "\n",
        "This assignment must be submitted by **11:59 PM** (**CET**) on **January 1, 2025**.\n",
        "\n",
        "\n",
        "**Group work**:\n",
        "\n",
        "You may work on this assignment in **groups of up to 4 students**. Only one member of the group is required to upload the completed Notebook solution to Aula Global. Please ensure that the submitted Notebook includes the f**ull names of all group members**.\n",
        "\n",
        "\n",
        "**Setup Instructions**\n",
        "\n",
        "\n",
        "\n",
        "1.   **Download the materials**: Access Aula Global (in the master group) and download the file provided for this assignment.\n",
        "2.   **Save the file**: Store the file in your private workspace. Ensure the downloaded folder contains the file named `Lab_filtering_student_24_25.ipynb`.\n",
        "3.   **Open the notebook**: Launch Google Colab and upload the notebook file.\n",
        "4.   **Initialize the environment**: Be patient while the Jupyter server initializes; this process may take a minute.\n",
        "\n",
        "Once the environment is ready, you can begin! The notebook is structured with dedicated sections for writing code solutions and answering questions.\n",
        "\n",
        "\n",
        "**Submitting the solution for the Jupyter Notebook**\n",
        "\n",
        "One member of the group must upload the final version of the Notebook file to Aula Global. Submissions can be made multiple times before the deadline; only the latest submission will be considered for grading.\n",
        "\n",
        "**Late Submission Policy**:\n",
        "*   Submissions **up to 1 day late** will incur a **20% penalty** on the final grade (applied to all group members).\n",
        "\n",
        "\n",
        "*   Submissions **up to 2 days late** will face a **40% penalty**, and so on."
      ],
      "metadata": {
        "id": "IdvVLAvD1HHW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Objective**\n",
        "\n",
        "Forecasting future values of time series is a critical challenge in fields such as finance, control systems, and signal processing. Filters like the Wiener filter and LMS adaptive filters are extensively used due to their mathematical rigor and effectiveness in handling noisy data. This assignment will guide students through the implementation of these filters and the evaluation of their performance using real-world stock market data."
      ],
      "metadata": {
        "id": "DjSE_6FK09cP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**What will the student do?**\n",
        "\n",
        "*   **Analyze real-world financial data**:\n",
        "    *   Work with data retrieved from Yahoo Finance for a selected stock (e.g., Apple, Microsoft). For this assignment, the dataset focuses on **Apple Inc. (AAPL)**, traded on the **NASDAQ market**.\n",
        "    *   Perform **Exploratory Data Analysis** (EDA) to examine stock price trends, identify noise patterns, and assess market volatility.\n",
        "\n",
        "\n",
        "*    **Implement predictive filters**:\n",
        "    *   **Wiener filter**: A fixed-parameter filter that leverages past autocorrelation of the data to compute an optimal prediction under stationary conditions.\n",
        "    *   **LMS adaptive filter**: A dynamic filter that continuously adjusts its parameters to adapt to changing trends and noise levels, making it suitable for non-stationary data.\n",
        "\n",
        "\n",
        "\n",
        "*   **Tune parameters**:\n",
        "    *  Experiment with **key filter parameters**, such as the order size for the Wiener filter and the learning rate for the LMS filter, to evaluate their impact on the prediction accuracy and adaptability to the data.\n",
        "\n",
        "*   **Compare filters**:\n",
        "\n",
        "    *  **Visualize the predictions** generated by each filter and compute error metrics (e.g., Mean Squared Error, Mean Absolute Error) to assess their performance and determine which filter is more effective under various conditions.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "C3ZuX371Tj8j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LET'S GET STARTED ðŸš€!**\n",
        "\n",
        "This assignment integrates theoretical concepts, practical implementation, and critical analysis to enhance students' comprehension of predictive filtering techniques.\n",
        "\n",
        "The process begins with setting up the environment with the necessary libraries. Once the setup is complete, students can proceed to the next section to initiate data collection and exploratory data analysis."
      ],
      "metadata": {
        "id": "fDzlXPswAIdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import yfinance as yf"
      ],
      "metadata": {
        "id": "qgAm-z6mCVV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.&nbsp;Apple Stock Data\n",
        "\n"
      ],
      "metadata": {
        "id": "0lfWqvirCBaQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Description\n",
        "\n",
        "The **Apple Stock Data** was retrieved from Yahoo Finance, covering the period from **January 1, 2020**, to **January 1, 2024**. It provides daily trading information for Apple Inc., a leading technology company listed on the NASDAQ stock exchange. The dataset includes key financial indicators that reflect Apple's market performance and investor behavior during the selected time frame.\n",
        "\n",
        "The dataset comprises **$1006$ daily records**, each containing **six numerical features** that offer insights into Apple's stock activity, including:\n",
        "*   **Open Price** (`Open`): The price of the stock at the beginning of each trading day.\n",
        "*   **High Price** (`High`): The highest price the stock reached during the trading day.\n",
        "*   **Low Price** (`Low`): The lowest price the stock reached during the trading day.\n",
        "*   **Close Price** (`Close`): The final price of the stock when the trading day ended.\n",
        "*   **Adjusted Close Price** (`Adj Close`): The closing price adjusted for dividends and stock splits.\n",
        "*   **Trading Volume** (`Volume`): The number of shares traded during the trading day.\n",
        "\n",
        "This dataset holds significant value for examining stock market trends, analyzing volatility, and understanding trading behavior. It serves as an excellent resource for evaluating historical market performance, developing predictive models, and benchmarking the performance of stock forecasting algorithms.\n",
        "\n",
        "\n",
        "For additional information about Apple's stock data, please refer to [Yahoo Finance's Apple Stock Page](https://finance.yahoo.com/quote/AAPL/?guccounter=1&guce_referrer=aHR0cHM6Ly9jaGF0Z3B0LmNvbS8&guce_referrer_sig=AQAAADp-JNEJGCt22jcXPGZH6MkDEe0c_kprUjI4Sc-qKhg7ltsRgEXd1nvaoNyuOZvTDc5TQOidEh-ySRciahQibvYK1m1ZC7ucdoF3Ynga3axeV4tLnbv5c-BOMEDBEXSGELA7aCJtNzYABbUvsq-Da_6QXz1pU6XhL5Y2pYlvlV9f). This source provides detailed historical and real-time data, along with insights into market trends and financial performance.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2Q5wJUpREQm1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Getting the data"
      ],
      "metadata": {
        "id": "eSHTA7MqXd_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, historical stock data for **Apple Inc. (AAPL**) will be retrieved from **Yahoo Finance** using the `yfinance` library, which was previously imported. The data covers the period from **January 1, 2020, to January 1, 2024**, encompassing four years of daily market activity.\n",
        "\n",
        "The provided code enables the collection and organization of raw data required for predictive filtering tasks. Once downloaded, the data will be stored in a `Pandas DataFrame`, which can be used for visualization, preprocessing, and further analysis."
      ],
      "metadata": {
        "id": "perIeILiXxOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch stock data\n",
        "stock_ticker = \"AAPL\"  # Apple Inc.\n",
        "data = yf.download(stock_ticker, start=\"2020-01-01\", end=\"2024-01-01\")"
      ],
      "metadata": {
        "id": "cxrQP9uBDGqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the download is successful, you should see a confirmation message similar to the following:\n",
        "\n",
        "`[*********************100%***********************]  1 of 1 completed`"
      ],
      "metadata": {
        "id": "tEr2vRKYDMN1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Dataset analysis\n",
        "\n",
        "\n",
        "Before proceeding with the analysis, it is important to examine the basic structure of the dataset by displaying its first few rows using the `head()` method. This step offers a quick overview of the data, including column names, the type of information contained (e.g., prices, volume), and the format of timestamps. Reviewing this preview helps ensure that the dataset has been loaded correctly and allows the identification of key features for subsequent analysis."
      ],
      "metadata": {
        "id": "2fUIwWl7SADW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze the data structure\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "EyUqXLNWXBd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To access a specific column in the dataset, the syntax `data['column_name']` can be used. For instance, to retrieve the stock's closing prices, the command `data['Close']` should be used. This approach facilitates the extraction and manipulation of individual columns for purposes such as analysis or visualization.\n",
        "\n"
      ],
      "metadata": {
        "id": "pDtnDWQrYcSM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question**:\n",
        "\n",
        "Using the `matplotlib` library, plot the stock's closing prices over time. Ensure that the x-axis represents the date, while the y-axis represents the stock price in USD. Add appropriate labels, a title, and a legend to make the plot clear and informative.\n",
        "\n"
      ],
      "metadata": {
        "id": "1TqqVzZpZ5pV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "# Plot the stock closing prices\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(data['Close'])\n",
        "plt.title(f\"{stock_ticker} Stock Closing Prices\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Stock Price (USD)\")\n",
        "plt.grid()\n",
        "plt.legend([stock_ticker])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PvlO1EcSXtvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Question**: What general trend do you observe in Apple's stock prices over the period shown? Based on this trend, what prediction would you make for the upcoming months after January 2024?\n",
        "\n",
        "<font color = 'green'> YOUR ANSWER HERE\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "DoT1DZvksPHP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far, `data['Close']` is a `DataFrame`, but it needs to be converted into a `NumPy` array to proceed with the rest of the assignment. Let's do it!"
      ],
      "metadata": {
        "id": "18leFekZCopT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to NumPy array\n",
        "close_prices = np.array(data['Close'])"
      ],
      "metadata": {
        "id": "TBdxmZ0uCVzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, it is important to note that this assignment involves **predicting 5 consecutive days**, allowing for an evaluation of the filters' ability to forecast stock prices over multiple days. This task is critical in financial analysis, as it reflects the need to understand trends and long-term dependencies. Multi-step prediction aligns with real-world scenarios where decisions often rely on projected movements over several days.\n",
        "\n",
        "While single-step prediction (one day) typically yields higher accuracy by minimizing error accumulation, it fails to capture the complexities of forecasting in dynamic environments like the stock market. By focusing on multi-step predictions, this assignment enables an assessment of the robustness of the Wiener and LMS filters in capturing AAPL stock trends and managing the inherent uncertainty in such forecasts.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Jj2zpNxFT7FX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Standardization of features\n",
        "In Lab 1 (*Machine Learning for Regression*) and Lab 2 (*Machine Learning for Classification*), the importance of feature standardization in machine learning algorithms was discussed. Standardization involves rescaling features to have a mean of zero and a standard deviation of one.\n",
        "\n",
        "Similarly, in signal processing tasks such as the Wiener and LMS filters, standardization is crucial for stable and efficient computations. It prevents numerical instabilities and facilitates faster convergence of the algorithms.\n",
        "\n",
        "In this lab, standardization will be applied using the [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) class from `scikit-learn`. This ensures that the filters operate optimally across the dataset and deliver reliable results."
      ],
      "metadata": {
        "id": "t3D0hoTdA_Mj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your task is as follows**:\n",
        "*   Use the `StandardScaler` class from the `sklearn.preprocessing module` to standardize `close_prices`."
      ],
      "metadata": {
        "id": "tNu2mtqxBDVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Here's how you can do it**:\n",
        "\n",
        "*  Create an instance of `StandardScaler`.\n",
        "*  Fit the scaler using the data (`close_prices`).\n",
        "*  Generate the new `NumPy` array as follows:\n",
        "    - `close_prices_normalized`: It contains the standardized version of `close_prices`, obtained by transforming it with the fitted scaler.\n",
        "    - Use `.ravel()` to flatten the resulting array, ensuring it matches the original shape of close_prices if it was one-dimensional initially."
      ],
      "metadata": {
        "id": "jPnQWtXNBH9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "# Import necessary libraries\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Step 1: Create an instance of StandardScaler\n",
        "close_prices_normalized = StandardScaler().fit_transform(close_prices).ravel()\n",
        "\n",
        "# Output the standardized close_prices\n",
        "print(\"Standardized close_prices:\", close_prices_normalized)\n"
      ],
      "metadata": {
        "id": "SJ5cvbWfBMaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's verify that everything is correct. To do this, running the following code should confirm that the mean of variable `close_prices_normalized` is $0$ and its variance (or standard deviation) is $1$."
      ],
      "metadata": {
        "id": "5WL5YA3nx46-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify the mean and standard deviation of close_prices_normalized\n",
        "mean = np.mean(close_prices_normalized)\n",
        "std_dev = np.std(close_prices_normalized)\n",
        "\n",
        "print(f\"The mean of `close_prices_normalized` is {mean:.4f}, and the standard deviation is {std_dev:.4f}.\")"
      ],
      "metadata": {
        "id": "mt8WOOTCxj2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before proceeding, it is essential to calculate the mean and standard deviation of the original closing prices. These values are crucial because they will later be used to **denormalize** the predictions made using the normalized data. Denormalization transforms the normalized predictions back to the original scale, enabling meaningful interpretation and accurate comparison with the actual stock prices.\n",
        "\n",
        "$\\underline{\\text{Note}}$: In this assignment, denormalization is necessary because the predictions generated by the Wiener and LMS filters are used to forecast stock prices on their original scale. Stock prices have real-world significance, and interpreting predictions directly in the normalized scale (mean $= 0$, standard deviation $= 1$) would lack practical value. By denormalizing, the predictions are converted back to their original scale, enabling direct comparison with actual stock prices and facilitating meaningful financial analysis.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Om0wvxs0BPkA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your task is as follows**:\n",
        "\n",
        "\n",
        "*   Calculate the mean and standard deviation of `close_prices`.\n",
        "*   Store these values in the variables `mean_close` and `std_close`, respectively.\n",
        "\n",
        "To perform these calculations, you can use the `mean` and `std` methods from the `NumPy` library.\n"
      ],
      "metadata": {
        "id": "BufyR_U7y7j9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#YOUR CODE HERE\n",
        "mean_close = np.mean(close_prices)\n",
        "std_close = np.std(close_prices)"
      ],
      "metadata": {
        "id": "GChiUSqkBSrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question**:\n",
        "\n",
        "If you already have the mean and standard deviation of the `close_prices` array (stored in `mean_close` and `std_close`), can you determine how to standardize the data in the same way as the `StandardScaler` class from `scikit-learn`? Write the code you would use."
      ],
      "metadata": {
        "id": "bvmMtAMSBWL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#YOUR CODE HERE\n",
        "close_prices_manual_normalized = (close_prices - mean_close) / std_close"
      ],
      "metadata": {
        "id": "WZ2TletVBbk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's verify that everything is correct. To do so, let's calculate the mean and standard deviation of `close_prices_manual_normalized`. If the standardization was performed correctly, the mean should be approximately $0$, and the standard deviation should be approximately $1$. Use the following code to perform the check:"
      ],
      "metadata": {
        "id": "Rw1PQBvc1cET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify the mean and standard deviation of close_prices_manual_normalized\n",
        "mean = np.mean(close_prices_manual_normalized)\n",
        "std_dev = np.std(close_prices_manual_normalized)\n",
        "\n",
        "print(f\"The mean of close_prices_manual_normalized is {mean:.4f}, and the standard deviation is {std_dev:.4f}.\")\n"
      ],
      "metadata": {
        "id": "jRP-8Yh61nKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.&nbsp;Evaluation metrics\n",
        "\n",
        "To evaluate the quality of the predictions, metrics such as MAE (Mean Absolute Error), MSE (Mean Squared Error), and RMSE (Root Mean Squared Error) will be calculated in this assignment. These metrics compare the predicted values with the actual signal values, offering insights into how well the model captures the underlying trends. Lower values for these metrics indicate better predictive performance. This step is essential for assessing the accuracy and reliability of the predictions made by both the Wiener and LMS filters.\n",
        "\n",
        "$\\underline{\\text{Note}}$: In this assignment, the coefficient $R^2$ is not ideal because it measures the proportion of variance explained relative to a baseline (e.g., the mean), which is less meaningful in time-series data like stock prices. Metrics like MAE, MSE, and RMSE are more suitable as they directly quantify prediction errors and align with the goal of minimizing error in filters like Wiener and LMS."
      ],
      "metadata": {
        "id": "qMB0h9zOJ90S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, a brief explanation of how each of these metrics is calculated and interpreted will be provided. This will help clarify their significance in evaluating the performance of predictions."
      ],
      "metadata": {
        "id": "0e0h1oQCKQzI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Mean Absolute Error (MAE)\n",
        "\n",
        "It measures the average absolute difference between actual and predicted values. Lower values indicate better accuracy, as predictions deviate less from the true values.\n",
        "\n",
        "  $\n",
        "\\text{MAE} = \\displaystyle \\frac{1}{N} \\sum\\limits_{i=1}^{N} \\left| y_{\\text{real}} - \\widehat{y}_{\\text{predicted}} \\right|\n",
        "$"
      ],
      "metadata": {
        "id": "-a4qIZvkKTHm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Mean Squared Error (MSE)\n",
        "\n",
        "It calculates the average of squared differences between actual and predicted values. Squaring the errors penalizes larger deviations more heavily, making it sensitive to outliers.\n",
        "\n",
        "  $\n",
        "\\text{MSE} = \\displaystyle \\frac{1}{N} \\sum\\limits_{i=1}^{N} \\big( y_{\\text{real}} - \\widehat{y}_{\\text{predicted}} \\big)^2\n",
        "$"
      ],
      "metadata": {
        "id": "fhsX3h6wKcdk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3  Root Mean Squared Error (RMSE)\n",
        "\n",
        "It represents the square root of MSE, providing a measure in the same unit as the original data. It balances penalizing large errors while remaining interpretable.\n",
        "\n",
        " $\n",
        "\\text{RMSE} = \\sqrt{\\displaystyle \\frac{1}{N} \\sum\\limits_{i=1}^{N} \\big( y_{\\text{real}} - \\widehat{y}_{\\text{predicted}} \\big)^2}\n",
        "$"
      ],
      "metadata": {
        "id": "FUZZ2Us8Knyk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.&nbsp;Wiener filter\n",
        "\n",
        "\n",
        "The **Wiener filter** is a foundational method in signal processing and prediction, designed to produce optimal estimates by minimizing the MSE. It determines fixed optimal weights using the entire dataset, under the assumption that the data exhibits stationary statistical properties. This makes it particularly effective for scenarios where the underlying data patterns remain stable over time.\n",
        "\n",
        "In this section, the student will implement the Wiener filter, apply it to predict future stock prices from the AAPL dataset, and evaluate its performance using metrics such as MAE, MSE, and RMSE. By comparing its predictions to those of the LMS filter, the objective will be to explore the advantages and constraints of fixed-weight filtering in stock price forecasting."
      ],
      "metadata": {
        "id": "erqMwpxnl5bp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Implementation of the `wiener_filter` function\n",
        "\n",
        "In this section, the student will implement the `wiener_filter` function. This function will be used to predict future stock prices based on past data, demonstrating the Wiener filter's ability to minimize mean squared error and showcasing its optimal predictive capabilities.\n",
        "\n"
      ],
      "metadata": {
        "id": "Tz8q1nZtK4mf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your task is as follows**:\n",
        "\n",
        "Implement the core steps of the Wiener filter for prediction. Follow these instructions to implement the most critical lines of the algorithm.\n",
        "\n"
      ],
      "metadata": {
        "id": "rJL8pLQDKkhI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1.   **Autocorrelation matrix**\n",
        "  *   Use the `np.lib.stride_tricks.sliding_window_view` function to create a new array **X**  that represents a sliding window view of the array signal (excluding its last element), with a window size defined by `order`. Each window should overlap with the previous one by one element. For example, if `signal = [1, 2, 3, 4, 5]` and `order = 3`, the resulting structure should be:\n",
        "\n",
        "                [[1, 2, 3],\n",
        "                [2, 3, 4],\n",
        "                [3, 4, 5]]\n",
        "\n",
        "   *   Compute the autocorrelation matrix **R** using the dot product of the sliding windows.  Normalize the result by dividing it by the number of rows in the windowed matrix.\n",
        "\n",
        "\n",
        "2.   **Cross-correlation vector**\n",
        "  *   Compute the cross-correlation vector **p** between the sliding windows and the corresponding future values of the signal. Ensure the future values are reshaped to align properly with the sliding windows.\n",
        "\n",
        "3.   **Optimal weights**\n",
        "\n",
        "  *   Find the optimal weights ($ \\mathbf{w}_\\text{opt}$) for the Wiener filter using the formula:\n",
        "\n",
        "$$ \\mathbf{w}_\\text{opt} = \\mathbf{R}^{-1} \\mathbf{p}$$\n",
        "\n",
        "4.   **Prediction**\n",
        "\n",
        "  *   Use the computed weights $ \\mathbf{w}_\\text{opt}$ and the most recent past values to calculate the next predicted value.\n"
      ],
      "metadata": {
        "id": "RvBgAhxFOjd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#YOUR CODE HERE\n",
        "def wiener_filter(signal, order, predict_steps):\n",
        "    \"\"\"\n",
        "    Applies the Wiener filter for prediction.\n",
        "\n",
        "    Parameters:\n",
        "      signal (array): Input signal (normalized prices).\n",
        "      order (int): Number of past values to consider.\n",
        "      predict_steps (int): Number of steps to predict.\n",
        "\n",
        "    Returns:\n",
        "      predicted_signal (array): Predicted values.\n",
        "    \"\"\"\n",
        "    n = len(signal)\n",
        "    predicted_signal = []\n",
        "\n",
        "    for step in range(predict_steps):\n",
        "        if step == 0:\n",
        "            # Selection of past values\n",
        "            past_values = signal[-order:]\n",
        "        else:\n",
        "            past_values = np.concatenate((signal[-order + step:], predicted_signal[:step]))\n",
        "\n",
        "        # Ensure that past_values has a length of order.\n",
        "        if len(past_values) < order:\n",
        "            past_values = np.pad(past_values, (order - len(past_values), 0), 'constant')\n",
        "\n",
        "\n",
        "        # 1. Construct the autocorrelation matrix and the cross-correlation vector\n",
        "        X = np.lib.stride_tricks.sliding_window_view(signal[:-1], window_shape = order)\n",
        "        R = np.dot(X.T, X) / X.shape[0]\n",
        "\n",
        "\n",
        "        # 2. Construct the cross-correlation vector\n",
        "        p = np.mean(X*signal[order:order + X.shape[0]].reshape(-1,1), axis = 0)\n",
        "\n",
        "        # 3. Find the optimal weights for the Wiener Filter\n",
        "        w_opt = np.dot(np.linalg.inv(R), p)\n",
        "\n",
        "        # 4. Make the prediction\n",
        "        prediction = np.dot(w_opt, past_values)\n",
        "        predicted_signal.append(prediction)\n",
        "\n",
        "    return np.array(predicted_signal)"
      ],
      "metadata": {
        "id": "r86KtiYwVhaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.1 Obtaining predictions\n",
        "\n",
        "After implementing the `wiener_filter` function,  it will be applied to generate predictions for AAPL stock prices."
      ],
      "metadata": {
        "id": "h-SHU41tAOkG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your task is as follows**:\n",
        "*   Initialize filter parameters:\n",
        "      *   `order = 10` (filter order)\n",
        "      *   `predicted_steps = 5` (number of steps to predict)\n",
        "\n",
        "* Apply the Wiener filter:\n",
        "\n",
        "   *   Use the `wiener_filter` function to obtain the predicted signal.\n",
        "   *   The filter should be applied to the normalized closing prices (`close_prices_normalized`) using the specified `order` (filter order) and `predicted_steps` (number of prediction steps).   \n",
        "\n",
        "\n",
        "* Denormalize the predictions.\n",
        "\n",
        "   *  To convert the predictions back to their original scale, use the following formula:\n",
        "     \n",
        "  $\\qquad \\text{denormalized} = (\\text{normalized} \\times \\text{scale_factor}) + \\text{offset}\n",
        "  $\n",
        "\n",
        "    where:  \n",
        "    *   `scale_factor` corresponds to the range or standard deviation used during normalization (variable `std_close` calculated in Section 1.4).\n",
        "    *   `offset` is the mean  value used to shift the data during normalization (variable `mean_close` computed in Section 1.4).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "j_QUDFV-A2vf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "order = 10\n",
        "predict_steps = 5"
      ],
      "metadata": {
        "id": "arY590iZBxyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "# Appling the Wiener filter\n",
        "wiener_predicted_signal_normalized = wiener_filter(close_prices_normalized, order, predict_steps)"
      ],
      "metadata": {
        "id": "dpj-7rMOC6D9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "# Denormalize predictions\n",
        "wiener_predicted_signal = mean_close + wiener_predicted_signal_normalized * std_close"
      ],
      "metadata": {
        "id": "-BeRr5jsFari"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your task is as follows**:\n",
        "*   Create a plot to visualize the actual closing prices and the Wiener predictions for AAPL. Use the following steps:\n",
        "      *   Plot the actual closing prices (`close_prices`) over the range of their indices with a label `Actual prices`.\n",
        "      *   Plot the predicted values (`wiener_predicted_signal`) over the extended range, starting from the end of the actual data. Label them as `Wiener predictions`.\n",
        "      *   Add appropriate labels for the X-axis (`Days`) and Y-axis (`Close price (USD)`).\n",
        "      *   Include a title for the plot: `Wiener Predictions for AAPL`.\n",
        "      *   Add a legend to distinguish between actual prices and predictions."
      ],
      "metadata": {
        "id": "CuQQzrmZGSAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: STUDENT CODE HERE\n",
        "# Get ranges of days for plotting\n",
        "days_actual = np.arange(len(close_prices))\n",
        "days_predicted = days_actual[-1]-predict_steps+1 + np.arange(predict_steps)\n",
        "\n",
        "# Plot the original and predicted closing prices\n",
        "plt.plot(days_actual, close_prices, label=\"Actual prices\")\n",
        "plt.plot(days_predicted + predict_steps, wiener_predicted_signal, 'r-', label=\"Wiener predictions\")\n",
        "plt.title(\"Wiener Predictions for AAPL\")\n",
        "plt.xlabel(\"Days\")\n",
        "plt.ylabel(\"Close price (USD)\")"
      ],
      "metadata": {
        "id": "vUgNBCjtB-wS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Evaluation of the Wiener filter\n",
        "\n",
        "To evaluate the quality of the Wiener predictions, the following metrics will be calculated: MAE, MSE, and RMSE (see Section 2 for further details).\n"
      ],
      "metadata": {
        "id": "0zF5pSk_HgD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your task is as follows**:\n",
        "*   **Calculate evaluation metrics**:\n",
        "  *   Using the predicted values from the Wiener filter (`wiener_predicted_signal`) and the actual values from the signal (`actual_values`), compute the following metrics: MAE, MSE, and RMSE.\n",
        "\n",
        "*   **Display results**:\n",
        "  *   Print the results in a formatted output to clearly show the values of each metric."
      ],
      "metadata": {
        "id": "VLBdSrn5L0YJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#YOUR CODE HERE\n",
        "from sklearn.metrics import mean_absolute_error, root_mean_squared_error\n",
        "\n",
        "# Actual values for comparison (last steps of the original signal)\n",
        "actual_values = close_prices[-predict_steps:]\n",
        "\n",
        "# Evaluate metrics\n",
        "mae = mean_absolute_error(actual_values, wiener_predicted_signal)\n",
        "rmse = root_mean_squared_error(actual_values, wiener_predicted_signal)\n",
        "mse = rmse ** 2\n",
        "\n",
        "# Print results\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")"
      ],
      "metadata": {
        "id": "Vza0LE3yMaup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Question**: What does the value of MAE mean in this context? How do you interpret this result?\n",
        "\n",
        "<font color = 'green'> Is represents the real error between the predicted values and the real ones in dollars. Because in the MSE we are doing the square error and in the RMSE we are doing the \"absolute value of the error. Because we are doing the square root of the power of the error.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "7iRf6BayOZBO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Question**: If you had to choose a metric to evaluate the quality of predictions, would you use MAE, MSE, or RMSE? Why?\n",
        "\n",
        "<font color = 'green'> I would use RMSE as it balances penalizing large errors.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "L-lhQm_KNjsy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Question**: Based on these values, do you think the Wiener filter provides accurate predictions? Why or why not?\n",
        "\n",
        "<font color = 'green'> As the results obtained in the metrics are close to 0 we can say that the Wiener filter is really good using this data for obtaining accurate predictions.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "qVNfP3UiOCJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Tune parameters of the Wiener filter\n",
        "\n",
        "In this section, the student will tune and analyze the impact of the Wiener filter parameters on the prediction quality of the signal `close_prices`. Specifically, the focus will be on exploring different filter orders and evaluating their effect on error metrics.\n",
        "\n",
        "Steps to follow:\n",
        "\n",
        "1.   **Parameters to explore**\n",
        "\n",
        "  Analyze how the filter order influences the Wiener filter's performance. Experiment with the following filter orders:\n",
        "  *   Filter orders: `[5, 10, 15, 20, 30, 40, 50]`\n",
        "\n",
        "\n",
        "2.   **Calculate the metrics**\n",
        "\n",
        "  For each filter order, compute the metrics MAE, MSE, and RMSE by comparing the predicted values (`wiener_predicted_signal`) with the actual values (`actual_values`). Determine the filter order that results in the lowest RMSE and store it as the optimal parameter.\n",
        "\n",
        "\n",
        "3.   **Print the results**\n",
        "\n",
        "  After evaluating all filter orders, display the optimal parameter and its corresponding RMSE."
      ],
      "metadata": {
        "id": "1hiHMXOOMtG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#YOUR CODE HERE\n",
        "filter_orders = [5, 10, 15, 20, 30, 40, 50]\n",
        "\n",
        "# DRY!\n",
        "def get_metrics(actual_values, wiener_predicted_signal):\n",
        "    mae = mean_absolute_error(actual_values, wiener_predicted_signal)\n",
        "    rmse = root_mean_squared_error(actual_values, wiener_predicted_signal)\n",
        "    mse = rmse ** 2\n",
        "    return [mae, mse, rmse]\n",
        "\n",
        "# Apply the filter and get the metrics\n",
        "predicted_signals_normalized = [ wiener_filter(close_prices_normalized, order, predict_steps) for order in filter_orders]\n",
        "predicted_signals_denormalized = [mean_close + signal * std_close for signal in predicted_signals_normalized]\n",
        "metrics = [get_metrics(actual_values, signal) for signal in predicted_signals_denormalized]\n",
        "rmses = [metric[2] for metric in metrics]\n",
        "\n",
        "# Get the best RMSE and its corresponding order\n",
        "rmse_min = np.min(rmses)\n",
        "best_wiener_order = filter_orders[np.argmin(rmses)]\n",
        "\n",
        "print(f'The best order is {best_wiener_order} with an RMSE of {rmse_min:.4f}.')"
      ],
      "metadata": {
        "id": "VXHm0NAhN4K4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Question**: What is the optimal filter order for the Wiener filter among the explored values?\n",
        "\n",
        "<font color = 'green'> In our case we have obtained that the best order for the wiener filter is 20\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "1aDaT3C_C_Y7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Question**: How does increasing the filter order affect the performance?\n",
        "\n",
        "<font color = 'green'> The computational cost increments when we increase the filter order.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "s-Tb91E8EqMY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.&nbsp;Adaptive filter\n",
        "\n",
        "The **LMS (Least Mean Squares) adaptive** filter is a powerful tool for prediction and signal processing. Unlike the Wiener filter, which computes fixed optimal weights from the entire dataset, the LMS filter dynamically updates its weights with each new data sample. This adaptability makes the LMS filter especially effective in non-stationary environments where data patterns change over time.\n",
        "\n",
        "In this section, students will implement the LMS filter, apply it to predict future stock prices, and evaluate its performance using metrics such as MAE, MSE, and RMSE. By comparing its predictions to those of the Wiener filter, the objective is to explore the strengths and limitations of adaptive filtering in the context of stock price forecasting.\n",
        "\n"
      ],
      "metadata": {
        "id": "mZyz_9e1PIJh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Implementation of the `lms_filter` function\n",
        "\n",
        "In this section, the student will implement the `lms_filter` function. This function will predict future stock prices based on past data, demonstrating the adaptive capabilities of the LMS filter."
      ],
      "metadata": {
        "id": "xIYlR9b2Qpr8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your task is as follows**:\n",
        "\n",
        "Implement the core steps of the LMS filter for prediction. Follow these instructions to implement the most critical lines of the algorithm.\n",
        "\n",
        "\n",
        "\n",
        "1.  **Initialize weights**\n",
        "\n",
        "  *   Begin by initializing the weight vector (`weights`) with small random values to avoid biasing the model. This ensures that the algorithm starts with unbiased weights near zero.\n",
        "  *   Use the `np.random.rand()`  function to generate a vector of size `order` with random values between $0$ and $1$. Scale these values  by multiplying them by $0.025$ to ensure the weights are sufficiently small.\n",
        "\n",
        "\n",
        "2.  **Select past values**\n",
        "\n",
        "  *   For each prediction step, extract the most recent order values from the signal to create the input for the filter:  \n",
        "       *   **First prediction step**: Use the last order elements of the signal as input.\n",
        "       *   **Subsequent Steps**: Combine the most recent elements of the signal with the previously predicted values to form the input for the filter.\n",
        "\n",
        "3.  **Ensure consistent input length**\n",
        "\n",
        "  *   If the length of `past_values` is less than `order` (e.g., at the beginning of the sequence), pad it with zeros to ensure it matches the required size.\n",
        "\n",
        "4.  **Prediction**\n",
        "\n",
        "  *   Calculate the predicted value by taking the dot product of the weight vector and the past values.\n",
        "\n",
        "5.  **Update weights**\n",
        "\n",
        "  *   **Compute prediction error**: If real future values of the signal are available, calculate the prediction error.\n",
        "  *   **Update Weights Dynamically**: Update the weights dynamically using the LMS formula.\n",
        "  \n",
        "          $\\mathbf{w}_\\text{new} = \\mathbf{w}_\\text{old} + \\mu \\cdot e \\cdot \\mathbf{x}$\n",
        "  \n"
      ],
      "metadata": {
        "id": "CbyTZY4eRCdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "def lms_filter(signal, order, predict_steps, learning_rate):\n",
        "    \"\"\"\n",
        "    LMS filter for prediction.\n",
        "\n",
        "    Parameters:\n",
        "        signal (array): Input signal (normalized).\n",
        "        order (int): Number of past values to consider.\n",
        "        predict_steps (int): Number of steps to predict.\n",
        "        learning_rate (float): Learning rate for weight updates.\n",
        "\n",
        "    Returns:\n",
        "        predicted_signal (array): Predicted values.\n",
        "        weights (array): Final weights after learning.\n",
        "    \"\"\"\n",
        "    n = len(signal)\n",
        "\n",
        "    # 1. Initialize weights to small random values, using a fixed RandomState\n",
        "    weights = np.random.RandomState(42).rand(order) * 0.025\n",
        "\n",
        "    predicted_signal = np.zeros(predict_steps)  # Array to store predictions\n",
        "\n",
        "    # 2. Select past values\n",
        "    for step in range(predict_steps):\n",
        "        # Use past values to predict the next step\n",
        "        if step == 0:\n",
        "            # Selection of past values for the first prediction step\n",
        "            past_values = signal[-order:]  # Use the last 'order' elements of the signal\n",
        "        else:\n",
        "            # For subsequent steps, combine recent elements of the signal with previous predictions\n",
        "            past_values = np.concatenate((signal[-(order - 1):], [predicted_signal[step - 1]]))\n",
        "\n",
        "        # 3. Ensure consistent input length\n",
        "        if len(past_values) < order:\n",
        "            past_values = np.pad(past_values, (order - len(past_values), 0), 'constant')\n",
        "\n",
        "        # 4. Prediction\n",
        "        prediction = np.dot(weights, past_values[-order:])  # Use the last 'order' values for prediction\n",
        "        predicted_signal[step] = prediction\n",
        "\n",
        "        # 5. Update weights (if there are real future values available)\n",
        "        if n + step < len(signal):\n",
        "            error = signal[n + step] - prediction  # Calculate prediction error\n",
        "            weights += learning_rate * error * past_values[-order:]  # Update weights\n",
        "\n",
        "    return predicted_signal, weights"
      ],
      "metadata": {
        "id": "1yS7tukYYQ48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.1 Obtaining predictions\n",
        "\n",
        "After implementing the `lms_filter` function,  it will be applied to generate predictions for AAPL stock prices."
      ],
      "metadata": {
        "id": "d6HvxTSy1el9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your task is as follows**:\n",
        "*   Initialize filter parameters:\n",
        "      *   `order = 100` (filter order)\n",
        "      *   `predicted_steps = 5` (number of steps to predict)\n",
        "      *   `learning_rate = 0.4` (step size of the weight update)\n",
        "\n",
        "*   Apply the Wiener filter:\n",
        "  *   Use the `lms_filter` function to obtain the predicted signal.\n",
        "  *   The filter should be applied to the normalized closing prices (`close_prices_normalized`) using the specified `order` (filter order), `predicted_steps` (number of prediction steps), and `learning_rate` (step size for weight updates).\n",
        "\n",
        "\n",
        "* Denormalize the predictions.\n",
        "\n",
        "   *  To convert the predictions back to their original scale, use the following formula:\n",
        "     \n",
        "  $\\qquad \\text{denormalized} = (\\text{normalized} \\times \\text{scale_factor}) + \\text{offset}\n",
        "  $\n",
        "\n",
        "    where:  \n",
        "    *   `scale_factor` corresponds to the range or standard deviation used during normalization (variable `std_close` calculated in Section 1.4).\n",
        "    *   `offset` is the mean  value used to shift the data during normalization (variable `mean_close` computed in Section 1.4).\n"
      ],
      "metadata": {
        "id": "9KQVlNRe64p4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "order = 100  # Filter order\n",
        "predict_steps = 5  # Number of steps to predict\n",
        "learning_rate = 0.4  # Step size for weight updates"
      ],
      "metadata": {
        "id": "4mkUdrr-7BBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "# Appling the LMS filter\n",
        "lms_predicted_signal_normalized, final_weights = lms_filter(\n",
        "    signal=close_prices_normalized,  # Normalized closing prices\n",
        "    order=order,                     # Filter order\n",
        "    predict_steps=predict_steps,     # Number of steps to predict\n",
        "    learning_rate=learning_rate      # Learning rate for weight updates\n",
        ")"
      ],
      "metadata": {
        "id": "GDs_UTmm7nSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "# Denormalize predictions\n",
        "lms_predicted_signal = (lms_predicted_signal_normalized * std_close) + mean_close\n",
        "# Display results\n",
        "print(\"LMS Predicted Normalized Signal:\", lms_predicted_signal_normalized)\n",
        "print(\"LMS Predicted Denormalized Signal:\", lms_predicted_signal)\n",
        "print(\"Final Weights:\", final_weights)"
      ],
      "metadata": {
        "id": "K1HTKWqV8iaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your task is as follows**:\n",
        "*   Create a plot to visualize the actual closing prices and the LMS predictions for AAPL. Use the following steps:\n",
        "      *   Plot the actual closing prices (`close_prices`) over the range of their indices with a label `Actual prices`.\n",
        "      *   Plot the predicted values (`lms_predicted_signal`) over the extended range, starting from the end of the actual data. Label them as `LMS predictions`.\n",
        "      *   Add appropriate labels for the X-axis (`Days`) and Y-axis (`Close price (USD)`).\n",
        "      *   Include a title for the plot: `Wiener Predictions for AAPL`.\n",
        "      *   Add a legend to distinguish between actual prices and predictions."
      ],
      "metadata": {
        "id": "S1qsKWk69fnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "# Run LMS filter\n",
        "predicted_signal, final_weights = lms_filter(close_prices_normalized, order, predict_steps, learning_rate)\n",
        "\n",
        "\n",
        "# Denormalize the predictions\n",
        "lms_predicted_signal = (predicted_signal * std_close) + mean_close\n",
        "\n",
        "\n",
        "# Create a range for the indices of actual prices and predictions\n",
        "days_actual = np.arange(len(close_prices))\n",
        "days_predicted = np.arange(len(close_prices), len(close_prices) + predict_steps)\n",
        "\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(days_actual, close_prices, label='Actual Prices', marker='o', color='blue')\n",
        "plt.plot(days_predicted, lms_predicted_signal, label='LMS Predictions', marker='x', color='orange')\n",
        "\n",
        "\n",
        "# Adding titles and labels\n",
        "plt.title('LMS Predictions for AAPL')\n",
        "plt.xlabel('Days')\n",
        "plt.ylabel('Close Price (USD)')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dZWpwr3RO2Eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Evaluation of the LMS filter\n",
        "\n",
        "To evaluate the quality of the LMS predictions, the following metrics will be calculated: MAE, MSE, and RMSE (see Section 2 for further details), just as was done with the Wiener filter.\n"
      ],
      "metadata": {
        "id": "s_yH4fjt_Mcp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your task is as follows**:\n",
        "*   **Calculate evaluation metrics**:\n",
        "  *   Using the predicted values from the Wiener filter (`lms_predicted_signal`) and the actual values from the signal (`actual_values`), compute the following metrics: MAE, MSE, and RMSE.\n",
        "\n",
        "*   **Display results**:\n",
        "  *   Print the results in a formatted output to clearly show the values of each metric."
      ],
      "metadata": {
        "id": "uukPTmBjARWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#YOUR CODE HERE\n",
        "# Actual values for comparison (last steps of the original signal)\n",
        "actual_values = close_prices[-predict_steps:]\n",
        "\n",
        "# Evaluate metrics\n",
        "mae = mean_absolute_error(actual_values, lms_predicted_signal)\n",
        "rmse = root_mean_squared_error(actual_values, lms_predicted_signal)\n",
        "mse = rmse ** 2\n",
        "\n",
        "# Print results\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")"
      ],
      "metadata": {
        "id": "axLKDk6ZAz6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Question**: Based on the calculated evaluation metrics (MAE, MSE, and RMSE) for both the Wiener and LMS filters when predicting 5 values:\n",
        "\n",
        "\n",
        "\n",
        "1.   Which filter demonstrates better predictive performance, and why?\n",
        "2.   What might explain the difference in performance between the two filters, considering their design and adaptability?\n",
        "\n",
        "\n",
        "\n",
        "<font color = 'green'> YOUR ANSWER HERE\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "asugfe7fKVEG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Tune parameters of the LMS filter\n",
        "\n",
        "In this section, the student will tune and analyze the impact of LMS filter parameters on the prediction quality of the signal `close_prices`. Specifically, the student will explore combinations of filter order and learning rate, and evaluate their effect on error metrics.\n",
        "\n",
        "\n",
        "In this section, the student will tune and analyze the impact of LMS  filter parameters on the prediction quality of the signal `close_prices`. Specifically, the focus will be on exploring  combinations of filter order and learning rate, and evaluate their effect on error metrics.\n",
        "\n",
        "**Steps to follow:**\n",
        "\n",
        "*   **Parameters to explore**\n",
        "\n",
        "  Analize how both filter order and learning rate influence the performance of the LMS filter. It will be experimented with the following values:\n",
        "  *   Filter orders: `[10, 50, 100, 150]`\n",
        "  *   Learning rates: `[0.1, 0.5, 1, 2, 5]`\n",
        "\n",
        "\n",
        "*   **Calculate the metrics**\n",
        "\n",
        "  For each parameter combination, compute the metrics MAE, MSE, and RMSE by comparing the predicted values (`lms_predicted_signal`) with the actual values (`actual_values`). Determine the filter order that results in the lowest RMSE and store it as the optimal parameter.\n",
        "\n",
        "*   **Print the results**\n",
        "\n",
        "   After evaluating all filter orders, display the optimal parameter and its corresponding RMSE.\n",
        "\n"
      ],
      "metadata": {
        "id": "kU85hItQGQlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#YOUR CODE HERE\n",
        "filter_orders = [10,50,100,150]  # Filter order values to experiment with\n",
        "learning_rates = [0.1,0.5,1,2,5]  # Learning rates to test\n",
        "\n",
        "best_lms_rmse = np.inf\n",
        "for order in filter_orders:\n",
        "    for learning_rate in learning_rates:\n",
        "        # Run LMS filter and get predictions\n",
        "        lms_predicted_signal, _ = lms_filter(close_prices_normalized, order, predict_steps, learning_rate)\n",
        "\n",
        "\n",
        "        # Denormalize predictions\n",
        "        lms_predicted_signal_denormalized = (lms_predicted_signal * std_close) + mean_close\n",
        "\n",
        "\n",
        "        # Actual values for comparison (last 'predict_steps' actual values)\n",
        "        actual_values = close_prices[-predict_steps:]\n",
        "\n",
        "\n",
        "        # Calculate metrics\n",
        "        mae = np.mean(np.abs(actual_values - lms_predicted_signal_denormalized))\n",
        "        mse = np.mean((actual_values - lms_predicted_signal_denormalized) ** 2)\n",
        "        rmse = np.sqrt(mse)\n",
        "\n",
        "\n",
        "        # Print results for the current combination\n",
        "        print(f\"Order: {order}, Learning Rate: {learning_rate:.1f} -> MAE: {mae:.4f}, MSE: {mse:.4f}, RMSE: {rmse:.4f}\")\n",
        "\n",
        "\n",
        "        # Check if this is the optimal parameter combination\n",
        "        if rmse < best_lms_rmse:\n",
        "            best_lms_rmse = rmse\n",
        "            best_lms_order = order\n",
        "            best_lms_learning_rate = learning_rate\n"
      ],
      "metadata": {
        "id": "hOz416rJEvJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "**Question**: How does increasing the filter order affect the performance?\n",
        "\n",
        "<font color = 'green'> The computation of the filter is more and more exÃ¨cnsive as the filter increase, it may improve the the effeciency</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "unmd81UwMCxl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "**Question**: What happens when the learning rate is too high?\n",
        "\n",
        "<font color = 'green'> It does not converge to any value.</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "kOHojb77MMZC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Question**: Are the optimal parameters intuitive? Why or why not?\n",
        "\n",
        "<font color = 'green'> YOUR ANSWER HERE\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "HCkB9M7aMSql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.&nbsp;Comparison of filters\n",
        "\n",
        "In this final section, it will be compared the performance of the Wiener filter and the LMS adaptive filter in predicting stock prices using the AAPL dataset. By evaluating their predictions against the actual stock prices, the goal is to understand the strengths and limitations of each filter in terms of prediction accuracy.\n",
        "\n",
        "Specifically, students will:\n",
        "\n",
        "1.   **Apply both filters** using their optimal configurations (best filter order and learning rate).\n",
        "2.   **Calculate error metrics** (MAE, MSE, and RMSE) for each filter to evaluate their predictive performance.\n",
        "3.   **Visualize the results** by plotting the actual stock prices  alongside the predictions from both filters.\n"
      ],
      "metadata": {
        "id": "h5FeqDQJRBTH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Your task is as follows**:\n",
        "\n",
        "*   **Define the optimal parameters**\n",
        "\n",
        "      Identify the optimal parameters for both filters. Use the best filter order for the Wiener filter and the best filter order and learning rate for the LMS filter.\n",
        "\n",
        "*   **Apply both filters**\n",
        "\n",
        "      Use the defined parameters to make predictions with both filters.\n",
        "\n",
        "*   **Calculate error metrics**\n",
        "\n",
        "      Evaluate the performance of both filters by calculating MAE, MSE, and RMSE for their predictions.\n",
        "\n",
        "*    **Compare the results**\n",
        "\n",
        "      Print the error metrics for both filters to see which performs better.\n",
        "\n",
        "*    **Visualize the predictions**\n",
        "\n",
        "      Plot the actual stock prices alongside the predictions from both filters for a clear visual comparison."
      ],
      "metadata": {
        "id": "NuHtDUD2tkQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: STUDENT CODE HERE\n",
        "\n",
        "# --- Best configurations for Wiener and LMS filters ---\n",
        "# Already obtained\n",
        "#best_wiener_order =\n",
        "#best_lms_order =\n",
        "#best_lms_learning_rate =\n",
        "\n",
        "# --- Apply Wiener filter ---\n",
        "predicted_signal_wiener_normalized = wiener_filter(close_prices_normalized, best_wiener_order, predict_steps)\n",
        "predicted_signal_wiener = mean_close + predicted_signal_wiener_normalized * std_close\n",
        "\n",
        "# --- Apply LMS filter ---\n",
        "predicted_signal_lms_normalized, _ = lms_filter(close_prices_normalized, best_lms_order, predict_steps, best_lms_learning_rate)\n",
        "predicted_signal_lms = mean_close + predicted_signal_lms_normalized * std_close\n",
        "\n",
        "# --- Calculate actual values for comparison ---\n",
        "# We already have this from before as well\n",
        "#actual_values =\n",
        "\n",
        "# --- Calculate error metrics for Wiener ---\n",
        "[mae_wiener, mse_wiener, rmse_wiener] = get_metrics(actual_values, predicted_signal_wiener)\n",
        "\n",
        "# --- Calculate error metrics for LMS ---\n",
        "[mae_lms, mse_lms, rmse_lms] = get_metrics(actual_values, predicted_signal_lms)\n",
        "\n",
        "# --- Print comparison ---\n",
        "print(\"Comparison of filters:\\n\")\n",
        "print(f\"Wiener Filter - MAE: {mae_wiener:.4f}, MSE: {mse_wiener:.4f}, RMSE: {rmse_wiener:.4f}\")\n",
        "print(f\"LMS Filter    - MAE: {mae_lms:.4f}, MSE: {mse_lms:.4f}, RMSE: {rmse_lms:.4f}\")\n",
        "\n",
        "# --- Plot results ---\n",
        "# Get ranges of days for plotting\n",
        "days_predicted = np.arange(len(close_prices), len(close_prices) + predict_steps)\n",
        "\n",
        "# Plot the original and predicted closing prices\n",
        "plt.plot(days_predicted, close_prices[-predict_steps:], label=\"Actual prices\")\n",
        "plt.plot(days_predicted, predicted_signal_wiener, 'r-', marker='o', label=\"Wiener predictions\")\n",
        "plt.plot(days_predicted, predicted_signal_lms, 'g-', marker='o', label=\"LMS predictions\")\n",
        "plt.title(\"Wiener and LMS predictions for AAPL\")\n",
        "plt.xlabel(\"Days\")\n",
        "plt.ylabel(\"Close price (USD)\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "7gHQJMs9RAwv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
